{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some of the packages\n",
    "import numpy as np\n",
    "\n",
    "# Generate three random sequences (not time series yet)\n",
    "M, S = 3, 100\n",
    "\n",
    "procs = np.random.randint(100, size=(M,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Added dataset \"None\" with properties: 3 processes, 100 observations, 1 replications\n"
     ]
    }
   ],
   "source": [
    "# Load the Data class\n",
    "from pynats.data import Data\n",
    "\n",
    "# Create an unnamed dataset with 3 processes and 1000 observations (1 replication)\n",
    "#   - dim_order specifies processes is the first dimension and samples/observations are the second\n",
    "#   - normalise z-scores the data\n",
    "data = Data(procs, dim_order='ps', normalise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading configuration file: /home/oliver/Dropbox/Workspace/code/research/pynats/pynats/config.yaml\n*** Importing module .correlation\n[0] Adding measure .correlation.pearsonr(x,y,{'cov_estimator': 'empirical'})...\nSuccesfully initialised with identifier \"pearsonr_empirical\"\n[1] Adding measure .correlation.pearsonr(x,y,{'cov_estimator': 'empirical', 'squared': True})...\nSuccesfully initialised with identifier \"pearsonr-sq_empirical\"\n[2] Adding measure .correlation.pearsonr(x,y,{'cov_estimator': 'ledoit_wolf'})...\nSuccesfully initialised with identifier \"pearsonr_ledoit_wolf\"\n[3] Adding measure .correlation.pearsonr(x,y,{'cov_estimator': 'shrunk'})...\nSuccesfully initialised with identifier \"pearsonr_shrunk\"\n[4] Adding measure .correlation.pearsonr(x,y,{'cov_estimator': 'oas'})...\nSuccesfully initialised with identifier \"pearsonr_oas\"\n[5] Adding measure .correlation.pcor(x,y,{'cov_estimator': 'empirical'})...\nSuccesfully initialised with identifier \"pcorr_empirical\"\n[6] Adding measure .correlation.pcor(x,y,{'cov_estimator': 'empirical', 'squared': True})...\nSuccesfully initialised with identifier \"pcorr-sq_empirical\"\n[7] Adding measure .correlation.pcor(x,y,{'cov_estimator': 'ledoit_wolf'})...\nSuccesfully initialised with identifier \"pcorr_ledoit_wolf\"\n[8] Adding measure .correlation.pcor(x,y,{'cov_estimator': 'shrunk'})...\nSuccesfully initialised with identifier \"pcorr_shrunk\"\n[9] Adding measure .correlation.pcor(x,y,{'cov_estimator': 'oas'})...\nSuccesfully initialised with identifier \"pcorr_oas\"\n[10] Adding measure .correlation.precision(x,y,{'cov_estimator': 'empirical', 'squared': False})...\nSuccesfully initialised with identifier \"prec_empirical\"\n[11] Adding measure .correlation.precision(x,y,{'cov_estimator': 'empirical', 'squared': True})...\nSuccesfully initialised with identifier \"prec-sq_empirical\"\n[12] Adding measure .correlation.spearmanr(x,y,{'squared': True})...\nSuccesfully initialised with identifier \"spearmanr-sq\"\n[13] Adding measure .correlation.spearmanr(x,y,{'squared': False})...\nSuccesfully initialised with identifier \"spearmanr\"\n[14] Adding measure .correlation.kendalltau(x,y,{'squared': True})...\nSuccesfully initialised with identifier \"kendalltau-sq\"\n[15] Adding measure .correlation.kendalltau(x,y,{'squared': False})...\nSuccesfully initialised with identifier \"kendalltau\"\n[16] Adding measure .correlation.xcorr(x,y,{'statistic': 'max'})...\nSuccesfully initialised with identifier \"xcorr_max\"\n[17] Adding measure .correlation.xcorr(x,y,{'statistic': 'max', 'squared': True})...\nSuccesfully initialised with identifier \"xcorr-sq_max\"\n[18] Adding measure .correlation.xcorr(x,y,{'statistic': 'mean'})...\nSuccesfully initialised with identifier \"xcorr_mean\"\n[19] Adding measure .correlation.xcorr(x,y,{'statistic': 'mean', 'squared': True})...\nSuccesfully initialised with identifier \"xcorr-sq_mean\"\n[20] Adding measure .correlation.dcorr(x,y)...\nSuccesfully initialised with identifier \"dcorr\"\n[21] Adding measure .correlation.mgc(x,y)...\nSuccesfully initialised with identifier \"mgc\"\n[22] Adding measure .correlation.hsic(x,y)...\nSuccesfully initialised with identifier \"hsic\"\n[23] Adding measure .correlation.hhg(x,y)...\nSuccesfully initialised with identifier \"hhg\"\n*** Importing module .causal\n[24] Adding measure .causal.anm(x,y)...\nSuccesfully initialised with identifier \"anm\"\n[25] Adding measure .causal.gpfit(x,y)...\nSuccesfully initialised with identifier \"gpfit\"\n[26] Adding measure .causal.cds(x,y)...\nSuccesfully initialised with identifier \"cds\"\n[27] Adding measure .causal.igci(x,y)...\nSuccesfully initialised with identifier \"igci\"\n[28] Adding measure .causal.reci(x,y)...\nSuccesfully initialised with identifier \"reci\"\n*** Importing module .temporal\n[29] Adding measure .temporal.coint(x,y,{'method': 'johansen', 'statistic': 'max_eig_stat'})...\nSuccesfully initialised with identifier \"coint_johansen_max_eig_stat\"\n[30] Adding measure .temporal.coint(x,y,{'method': 'johansen', 'statistic': 'trace_stat'})...\nSuccesfully initialised with identifier \"coint_johansen_trace_stat\"\n[31] Adding measure .temporal.coint(x,y,{'method': 'aeg', 'statistic': 'tstat'})...\nSuccesfully initialised with identifier \"coint_aeg_tstat\"\n[32] Adding measure .temporal.coint(x,y,{'method': 'aeg', 'statistic': 'pvalue'})...\nSuccesfully initialised with identifier \"coint_aeg_pvalue\"\n[33] Adding measure .temporal.ccm(x,y,{'statistic': 'mean'})...\nSuccesfully initialised with identifier \"ccm_mean\"\n[34] Adding measure .temporal.ccm(x,y,{'statistic': 'max'})...\nSuccesfully initialised with identifier \"ccm_max\"\n[35] Adding measure .temporal.ccm(x,y,{'statistic': 'diff'})...\nSuccesfully initialised with identifier \"ccm_diff\"\n[36] Adding measure .temporal.mgcx(x,y,{'max_lag': 5})...\nSuccesfully initialised with identifier \"mgcx\"\n[37] Adding measure .temporal.dcorrx(x,y,{'max_lag': 5})...\nSuccesfully initialised with identifier \"dcorrx\"\n*** Importing module .spectral\n[38] Adding measure .spectral.coherence(x,y,{'f_lb': 0.0, 'f_ub': 0.2})...\nSuccesfully initialised with identifier \"coh_fs-1_flb-00_fub-02\"\n[39] Adding measure .spectral.coherence(x,y,{'f_lb': 0.02, 'f_ub': 10})...\nSuccesfully initialised with identifier \"coh_fs-1_flb-002_fub-10\"\n[40] Adding measure .spectral.icoherence(x,y)...\nSuccesfully initialised with identifier \"icoh_fs-1_flb-00_fub-02\"\n[41] Adding measure .spectral.phase(x,y)...\nSuccesfully initialised with identifier \"phase_fs-1_flb-00_fub-02\"\n[42] Adding measure .spectral.phase_lag(x,y)...\nSuccesfully initialised with identifier \"phase-lag_fs-1_flb-00_fub-02\"\n[43] Adding measure .spectral.weighted_phase_lag(x,y)...\nSuccesfully initialised with identifier \"w-phase-lag_fs-1_flb-00_fub-02\"\n[44] Adding measure .spectral.debiased_squared_weighted_phase_lag(x,y)...\nSuccesfully initialised with identifier \"dsqw-phase-lag_fs-1_flb-00_fub-02\"\n[45] Adding measure .spectral.partial_coherence(x,y)...\nSuccesfully initialised with identifier \"pcoh_t-1_flb-002_fub-015\"\n[46] Adding measure .spectral.partial_directed_coherence(x,y)...\nSuccesfully initialised with identifier \"pdcoh_fs-1_flb-00_fub-02\"\n[47] Adding measure .spectral.directed_transfer_function(x,y)...\nSuccesfully initialised with identifier \"dtf_fs-1_flb-00_fub-02\"\n[48] Adding measure .spectral.spectral_granger(x,y,{'fs': 1})...\nSuccesfully initialised with identifier \"sgc_fs-1_flb-00_fub-02_o-None\"\n[49] Adding measure .spectral.spectral_granger(x,y,{'fs': 1, 'order': 1})...\nSuccesfully initialised with identifier \"sgc_fs-1_flb-00_fub-02_o-1\"\n[50] Adding measure .spectral.spectral_granger(x,y,{'fs': 1, 'order': 20})...\nSuccesfully initialised with identifier \"sgc_fs-1_flb-00_fub-02_o-20\"\n*** Importing module .wavelet\n[51] Adding measure .wavelet.wcoh(x,y)...\nSuccesfully initialised with identifier \"wcoh_fs-1_w1-30_tlb-0_tub-inf_flb-0_fub-inf\"\n*** Importing module .infotheory\n[52] Adding measure .infotheory.conditional_entropy(x,y,{'estimator': 'gaussian'})...\nSuccesfully initialised with identifier \"ce_gaussian\"\n[53] Adding measure .infotheory.conditional_entropy(x,y,{'estimator': 'kozachenko'})...\nSuccesfully initialised with identifier \"ce_kozachenko\"\n[54] Adding measure .infotheory.conditional_entropy(x,y,{'estimator': 'kernel'})...\nSuccesfully initialised with identifier \"ce_kernel_W-0.5\"\n[55] Adding measure .infotheory.causal_entropy(x,y,{'estimator': 'gaussian'})...\nSuccesfully initialised with identifier \"cce_gaussian\"\n[56] Adding measure .infotheory.causal_entropy(x,y,{'estimator': 'kozachenko'})...\nSuccesfully initialised with identifier \"cce_kozachenko\"\n[57] Adding measure .infotheory.causal_entropy(x,y,{'estimator': 'kernel'})...\nSuccesfully initialised with identifier \"cce_kernel_W-0.5\"\n[58] Adding measure .infotheory.directed_info(x,y,{'estimator': 'gaussian'})...\nSuccesfully initialised with identifier \"di_gaussian\"\n[59] Adding measure .infotheory.directed_info(x,y,{'estimator': 'kozachenko'})...\nSuccesfully initialised with identifier \"di_kozachenko\"\n[60] Adding measure .infotheory.directed_info(x,y,{'estimator': 'kernel'})...\nSuccesfully initialised with identifier \"di_kernel_W-0.5\"\n[61] Adding measure .infotheory.stochastic_interaction(x,y,{'estimator': 'gaussian'})...\nSuccesfully initialised with identifier \"si_gaussian\"\n[62] Adding measure .infotheory.stochastic_interaction(x,y,{'estimator': 'kozachenko'})...\nSuccesfully initialised with identifier \"si_kozachenko\"\n[63] Adding measure .infotheory.stochastic_interaction(x,y,{'estimator': 'kernel'})...\nSuccesfully initialised with identifier \"si_kernel_W-0.5\"\n[64] Adding measure .infotheory.mutual_info(x,y,{'estimator': 'gaussian'})...\nSuccesfully initialised with identifier \"mi_gaussian\"\n[65] Adding measure .infotheory.mutual_info(x,y,{'estimator': 'kraskov', 'prop_k': 4})...\nSuccesfully initialised with identifier \"mi_kraskov_NN-4\"\n[66] Adding measure .infotheory.mutual_info(x,y,{'estimator': 'kraskov', 'prop_k': 4, 'dyn_corr_excl': 'AUTO'})...\nSuccesfully initialised with identifier \"mi_kraskov_NN-4_DCE\"\n[67] Adding measure .infotheory.mutual_info(x,y,{'estimator': 'kernel', 'kernel_width': 0.25})...\nSuccesfully initialised with identifier \"mi_kernel_W-0.25\"\n[68] Adding measure .infotheory.time_lagged_mutual_info(x,y,{'estimator': 'gaussian'})...\nSuccesfully initialised with identifier \"tl_mi_gaussian\"\n[69] Adding measure .infotheory.time_lagged_mutual_info(x,y,{'estimator': 'kraskov', 'prop_k': 4})...\nSuccesfully initialised with identifier \"tl_mi_kraskov_NN-4\"\n[70] Adding measure .infotheory.time_lagged_mutual_info(x,y,{'estimator': 'kraskov', 'prop_k': 4, 'dyn_corr_excl': 'AUTO'})...\nSuccesfully initialised with identifier \"tl_mi_kraskov_NN-4_DCE\"\n[71] Adding measure .infotheory.time_lagged_mutual_info(x,y,{'estimator': 'kernel', 'kernel_width': 0.25})...\nSuccesfully initialised with identifier \"tl_mi_kernel_W-0.25\"\n[72] Adding measure .infotheory.transfer_entropy(x,y,{'estimator': 'kraskov', 'prop_k': 4, 'auto_embed_method': 'MAX_CORR_AIS', 'k_search_max': 10, 'tau_search_max': 4, 'dyn_corr_excl': 'AUTO'})...\nSuccesfully initialised with identifier \"te_kraskov_NN-4_DCE_k-max-10_tau-max-4\"\n[73] Adding measure .infotheory.transfer_entropy(x,y,{'estimator': 'kraskov', 'prop_k': 4, 'auto_embed_method': 'MAX_CORR_AIS', 'k_search_max': 10, 'tau_search_max': 1, 'dyn_corr_excl': 'AUTO'})...\nSuccesfully initialised with identifier \"te_kraskov_NN-4_DCE_k-max-10_tau-max-1\"\n[74] Adding measure .infotheory.transfer_entropy(x,y,{'estimator': 'kraskov', 'prop_k': 4, 'k_history': 2, 'l_history': 1, 'dyn_corr_excl': 'AUTO'})...\nSuccesfully initialised with identifier \"te_kraskov_NN-4_DCE_k-2_kt-1_l-1_lt-1\"\n[75] Adding measure .infotheory.transfer_entropy(x,y,{'estimator': 'kraskov', 'prop_k': 4, 'k_history': 1, 'l_history': 1, 'dyn_corr_excl': 'AUTO'})...\nSuccesfully initialised with identifier \"te_kraskov_NN-4_DCE_k-1_kt-1_l-1_lt-1\"\n[76] Adding measure .infotheory.transfer_entropy(x,y,{'estimator': 'kraskov', 'prop_k': 4, 'k_history': 1, 'l_history': 1})...\nSuccesfully initialised with identifier \"te_kraskov_NN-4_k-1_kt-1_l-1_lt-1\"\n[77] Adding measure .infotheory.transfer_entropy(x,y,{'estimator': 'kernel', 'kernel_width': 0.25, 'k_history': 1, 'l_history': 1})...\nSuccesfully initialised with identifier \"te_kernel_W-0.25_k-1\"\n[78] Adding measure .infotheory.transfer_entropy(x,y,{'estimator': 'gaussian', 'auto_embed_method': 'MAX_CORR_AIS', 'k_search_max': 10, 'tau_search_max': 2})...\nSuccesfully initialised with identifier \"te_gaussian_k-max-10_tau-max-2\"\n[79] Adding measure .infotheory.transfer_entropy(x,y,{'estimator': 'gaussian', 'k_history': 1, 'l_history': 1})...\nSuccesfully initialised with identifier \"te_gaussian_k-1_kt-1_l-1_lt-1\"\nNumber of pairwise measures: 80\n"
     ]
    }
   ],
   "source": [
    "# Load the Calculator class\n",
    "from pynats.calculator import Calculator\n",
    "\n",
    "# Let's create an unnamed calculator\n",
    "calc = Calculator(dataset=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing [None: te_gaussian_k-1_kt-1_l-1_lt-1]: 100%|██████████| 80/80 [00:04<00:00, 16.07it/s]\n"
     ]
    }
   ],
   "source": [
    "calc.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(80, 3, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Should be an adjacency matrix of features x processes x processes\n",
    "calc.adjacency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}